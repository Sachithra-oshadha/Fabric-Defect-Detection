{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxaZVwBNHmAWvC5E9ZUt/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sachithra-oshadha/Fabric-Defect-Detection/blob/main/01_Yolov8_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32GcublMFwXo",
        "outputId": "4297f4f2-7a2c-4786-95a7-ae5c0e07f2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.203-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.203-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.203 ultralytics-thop-2.0.17\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.9-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.8.3)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.3)\n",
            "Downloading roboflow-1.2.9-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 roboflow-1.2.9\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install roboflow\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crMeDji6F1iq",
        "outputId": "6c40752b-6a78-463b-d417-992051e55d8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "Number of GPUs: 1\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR0WUxn6F9DC",
        "outputId": "0015c637-c3a8-42fc-e56c-137ce24f155d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8'"
      ],
      "metadata": {
        "id": "v2IuMiE8GBFE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset structure:\")\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    level = root.replace(dataset_path, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:10]:  # Show first 10 files only\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 10:\n",
        "        print(f\"{subindent}... and {len(files) - 10} more files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RhRku9jGi3Q",
        "outputId": "2996d11c-0599-44e6-b66c-de0cf53767fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset structure:\n",
            "24_09_2025_Research.v1i.yolov8/\n",
            "  README.roboflow.txt\n",
            "  README.dataset.txt\n",
            "  data.yaml\n",
            "  valid/\n",
            "    labels/\n",
            "      015912_jpg.rf.30dcc20c58cafd3b51a9494e892fa29c.txt\n",
            "      015927_jpg.rf.9cc0a8690f44ea0a48dfcc132415a74c.txt\n",
            "      015947_jpg.rf.b16f354a688233877f1565a09bed434c.txt\n",
            "      015895_jpg.rf.5f55dee1a68c84281cffae15093ee4f8.txt\n",
            "      015932_jpg.rf.6bff0821b7c201fcadde20d51aecd0c3.txt\n",
            "      015901_jpg.rf.4a26703ca64fa4d6f69673422e2780f8.txt\n",
            "      015971_jpg.rf.f62bb99ee3bd6708c78166d3618bd533.txt\n",
            "      015940_jpg.rf.b347b4fc09e5b4b4e82882cc98deb244.txt\n",
            "      015946_jpg.rf.c579bcb7fe17854ed82adae55a3bec23.txt\n",
            "      015889_jpg.rf.1696e0b0c7dc2081e7a311be021fc955.txt\n",
            "      ... and 244 more files\n",
            "    images/\n",
            "      016088_jpg.rf.62143ddb796e5312ddcc3fb5e3454cb0.jpg\n",
            "      015984_jpg.rf.7532489a489e43ab87a5dfe817c6b4cb.jpg\n",
            "      020014_jpg.rf.148fbab0d9a15646f6984820b9d7ae2c.jpg\n",
            "      016077_jpg.rf.9cf076c9a8b65276664493cd94423f04.jpg\n",
            "      015978_jpg.rf.6da9a022e730930bd952727d3209bdb2.jpg\n",
            "      020219_jpg.rf.be5bec8ed6a881df2b18a5df3c428555.jpg\n",
            "      020140_jpg.rf.d76d34f4a12646576c2ad2eb047dbc4f.jpg\n",
            "      015993_jpg.rf.3d47e563d40341cf8c44b627568cab8c.jpg\n",
            "      016029_jpg.rf.0687ad56fc8d775e19d71e9362021382.jpg\n",
            "      015946_jpg.rf.c579bcb7fe17854ed82adae55a3bec23.jpg\n",
            "      ... and 244 more files\n",
            "  train/\n",
            "    labels/\n",
            "      044315_jpg.rf.8b451dfad9bf0ccb22f97e3eab2f122f.txt\n",
            "      044553_jpg.rf.21c10abc96a1134cd46ed25e6284b22f.txt\n",
            "      060500_jpg.rf.068ccc1705d993ba9b2b398531ce4eb0.txt\n",
            "      044553_jpg.rf.0438f8b53f0cc82a4c346d066d672bdf.txt\n",
            "      044349_jpg.rf.1ec4f9ee419e1a2c421b3e6d33a7d4f9.txt\n",
            "      044382_jpg.rf.9ba25cb87e8dd1796a49099f83738438.txt\n",
            "      044545_jpg.rf.49d34692328d271768ba3db995306c7d.txt\n",
            "      044238_jpg.rf.9e440fb9dc9f7bb5076a4c40d6cde40e.txt\n",
            "      044229_jpg.rf.b8b77c74f291f972cab83eb1e8640c2a.txt\n",
            "      044267_jpg.rf.5470d4de59392698d9456da8ad93ea86.txt\n",
            "      ... and 3027 more files\n",
            "    images/\n",
            "      044511_jpg.rf.e2b06bd6b9bb667f70d712e9ffe0ca13.jpg\n",
            "      044229_jpg.rf.b8b77c74f291f972cab83eb1e8640c2a.jpg\n",
            "      043885_jpg.rf.9cb5f29efb460b2e081dbe5a45973081.jpg\n",
            "      044156_jpg.rf.96fb6b691a7165c418eb553daa005668.jpg\n",
            "      044315_jpg.rf.8b451dfad9bf0ccb22f97e3eab2f122f.jpg\n",
            "      044386_jpg.rf.66b64a18e7bb6e96c1037643a81e770f.jpg\n",
            "      044179_jpg.rf.e87190273427c5c6487be0a47c1cd7c8.jpg\n",
            "      044482_jpg.rf.7c66d94b9847ee5ced1583e90b25ad71.jpg\n",
            "      044037_jpg.rf.a362e07e6e6f8a7736a9dd61421f0097.jpg\n",
            "      044304_jpg.rf.b819829993a13d1f1ba9a458bcc386df.jpg\n",
            "      ... and 3027 more files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_path = os.path.join(dataset_path, 'data.yaml')\n",
        "\n",
        "print(\"Current data.yaml content:\")\n",
        "with open(yaml_path, 'r') as file:\n",
        "    yaml_content = yaml.safe_load(file)\n",
        "    print(yaml.dump(yaml_content, default_flow_style=False))\n",
        "\n",
        "# Update paths to absolute paths for Colab\n",
        "yaml_content['path'] = dataset_path\n",
        "yaml_content['train'] = 'train/images'\n",
        "yaml_content['val'] = 'valid/images'\n",
        "\n",
        "# Save the updated yaml file\n",
        "with open(yaml_path, 'w') as file:\n",
        "    yaml.dump(yaml_content, file, default_flow_style=False)\n",
        "\n",
        "print(\"\\nUpdated data.yaml content:\")\n",
        "with open(yaml_path, 'r') as file:\n",
        "    print(file.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMDjKYW3GlxA",
        "outputId": "c5cc865c-f2d0-4428-9c1d-b1d823b477c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current data.yaml content:\n",
            "names:\n",
            "- Hole\n",
            "- Snag\n",
            "- Stain\n",
            "nc: 3\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: 24_09_2025_research-xcb6g\n",
            "  url: https://universe.roboflow.com/vindya-wsss4/24_09_2025_research-xcb6g/dataset/1\n",
            "  version: 1\n",
            "  workspace: vindya-wsss4\n",
            "test: ../test/images\n",
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "\n",
            "Updated data.yaml content:\n",
            "names:\n",
            "- Hole\n",
            "- Snag\n",
            "- Stain\n",
            "nc: 3\n",
            "path: /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: 24_09_2025_research-xcb6g\n",
            "  url: https://universe.roboflow.com/vindya-wsss4/24_09_2025_research-xcb6g/dataset/1\n",
            "  version: 1\n",
            "  workspace: vindya-wsss4\n",
            "test: ../test/images\n",
            "train: train/images\n",
            "val: valid/images\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(directory):\n",
        "    \"\"\"Count files in a directory\"\"\"\n",
        "    if os.path.exists(directory):\n",
        "        return len([f for f in os.listdir(directory) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.txt'))])\n",
        "    return 0\n",
        "\n",
        "# Count images and labels\n",
        "train_images = count_files(os.path.join(dataset_path, 'train', 'images'))\n",
        "train_labels = count_files(os.path.join(dataset_path, 'train', 'labels'))\n",
        "valid_images = count_files(os.path.join(dataset_path, 'valid', 'images'))\n",
        "valid_labels = count_files(os.path.join(dataset_path, 'valid', 'labels'))\n",
        "\n",
        "print(f\"Dataset Statistics:\")\n",
        "print(f\"Training - Images: {train_images}, Labels: {train_labels}\")\n",
        "print(f\"Validation - Images: {valid_images}, Labels: {valid_labels}\")\n",
        "\n",
        "# Check for class distribution\n",
        "def analyze_classes(labels_dir):\n",
        "    \"\"\"Analyze class distribution in label files\"\"\"\n",
        "    class_counts = {}\n",
        "    total_objects = 0\n",
        "\n",
        "    if os.path.exists(labels_dir):\n",
        "        for label_file in os.listdir(labels_dir):\n",
        "            if label_file.endswith('.txt'):\n",
        "                label_path = os.path.join(labels_dir, label_file)\n",
        "                with open(label_path, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "                    for line in lines:\n",
        "                        if line.strip():\n",
        "                            class_id = int(line.split()[0])\n",
        "                            class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
        "                            total_objects += 1\n",
        "\n",
        "    return class_counts, total_objects\n",
        "\n",
        "train_classes, train_objects = analyze_classes(os.path.join(dataset_path, 'train', 'labels'))\n",
        "valid_classes, valid_objects = analyze_classes(os.path.join(dataset_path, 'valid', 'labels'))\n",
        "\n",
        "print(f\"\\nClass Distribution:\")\n",
        "print(f\"Training set - Classes: {train_classes}, Total objects: {train_objects}\")\n",
        "print(f\"Validation set - Classes: {valid_classes}, Total objects: {valid_objects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdd0aasgG4aT",
        "outputId": "bec456b4-08da-4152-b021-db162f81e734"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Statistics:\n",
            "Training - Images: 3037, Labels: 3037\n",
            "Validation - Images: 254, Labels: 254\n",
            "\n",
            "Class Distribution:\n",
            "Training set - Classes: {0: 390, 2: 780, 1: 1522}, Total objects: 2692\n",
            "Validation set - Classes: {1: 148, 2: 73, 0: 26}, Total objects: 247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')  # This will download the pretrained weights\n",
        "\n",
        "# Display model information\n",
        "model.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhUWJJLbHAQq",
        "outputId": "2fb9e103-9e32-43f6-c418-bb1a38919943"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 103.9MB/s 0.1s\n",
            "YOLOv8n summary: 129 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 3157200, 0, 8.8575488)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training configuration\n",
        "training_config = {\n",
        "    'data': yaml_path,           # Path to data.yaml\n",
        "    'epochs': 25,               # Number of training epochs\n",
        "    'batch': 16,                 # Batch size (adjust based on GPU memory)\n",
        "    'imgsz': 640,               # Image size\n",
        "    'device': 0,                 # GPU device (0 for first GPU, 'cpu' for CPU)\n",
        "    'workers': 2,                # Number of worker processes\n",
        "    'project': '/content/runs',  # Project directory\n",
        "    'name': 'fabric_defect_detection',  # Experiment name\n",
        "    'exist_ok': True,           # Allow overwriting existing experiment\n",
        "    'pretrained': True,         # Use pretrained weights\n",
        "    'optimizer': 'SGD',         # Optimizer (SGD, Adam, AdamW)\n",
        "    'lr0': 0.01,               # Initial learning rate\n",
        "    'lrf': 0.1,                # Final learning rate factor\n",
        "    'momentum': 0.937,         # SGD momentum\n",
        "    'weight_decay': 0.0005,    # Optimizer weight decay\n",
        "    'warmup_epochs': 3,        # Warmup epochs\n",
        "    'warmup_momentum': 0.8,    # Warmup initial momentum\n",
        "    'box': 7.5,                # Box loss gain\n",
        "    'cls': 0.5,                # Class loss gain\n",
        "    'dfl': 1.5,                # DFL loss gain\n",
        "    'patience': 10,            # Early stopping patience\n",
        "    'save': True,              # Save checkpoints\n",
        "    'save_period': -1,         # Save checkpoint every x epochs (-1 to disable)\n",
        "    'cache': False,            # Use image caching (True/False/'ram')\n",
        "}\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "for key, value in training_config.items():\n",
        "    print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWoEMQ3HHVgl",
        "outputId": "147719c6-7088-45ab-c903-bf41f22b8697"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Configuration:\n",
            "  data: /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/data.yaml\n",
            "  epochs: 25\n",
            "  batch: 16\n",
            "  imgsz: 640\n",
            "  device: 0\n",
            "  workers: 2\n",
            "  project: /content/runs\n",
            "  name: fabric_defect_detection\n",
            "  exist_ok: True\n",
            "  pretrained: True\n",
            "  optimizer: SGD\n",
            "  lr0: 0.01\n",
            "  lrf: 0.1\n",
            "  momentum: 0.937\n",
            "  weight_decay: 0.0005\n",
            "  warmup_epochs: 3\n",
            "  warmup_momentum: 0.8\n",
            "  box: 7.5\n",
            "  cls: 0.5\n",
            "  dfl: 1.5\n",
            "  patience: 10\n",
            "  save: True\n",
            "  save_period: -1\n",
            "  cache: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Start training\n",
        "results = model.train(**training_config)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MntaX8gaHpMM",
        "outputId": "979da6a9-5fdd-41ba-c915-e89d63c53b60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "STARTING TRAINING\n",
            "==================================================\n",
            "Ultralytics 8.3.203 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.1, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fabric_defect_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/fabric_defect_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 27.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 92.4MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 1.5¬±1.7 ms, read: 0.1¬±0.1 MB/s, size: 71.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/train/labels... 3037 images, 1535 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3037/3037 30.4it/s 1:40\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 2.5¬±1.2 ms, read: 0.2¬±0.0 MB/s, size: 76.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/labels... 254 images, 119 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 254/254 62.7it/s 4.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/labels.cache\n",
            "Plotting labels to /content/runs/fabric_defect_detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/25      2.07G      1.944          4      1.906         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 2.8it/s 1:07\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.6it/s 4.9s\n",
            "                   all        254        247      0.626      0.227      0.232      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/25      2.54G      1.858      2.762       1.76         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.3it/s 2.4s\n",
            "                   all        254        247      0.251      0.367      0.169     0.0551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/25      2.56G       1.93      2.533      1.834          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.2it/s 2.5s\n",
            "                   all        254        247      0.316      0.213      0.144     0.0545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/25      2.57G      1.996      2.449      1.914         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.1it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.5it/s 3.2s\n",
            "                   all        254        247      0.398      0.331      0.313      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/25      2.58G      1.977      2.303      1.872         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.1it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.2it/s 2.5s\n",
            "                   all        254        247      0.166      0.214     0.0863     0.0315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/25      2.59G      1.888      2.106      1.805         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.4it/s 2.3s\n",
            "                   all        254        247      0.476      0.461      0.447      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/25       2.6G      1.865      2.022       1.76         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.7it/s 3.0s\n",
            "                   all        254        247      0.388      0.527      0.454      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/25      2.61G      1.813      1.922      1.737         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.5it/s 2.3s\n",
            "                   all        254        247      0.399      0.604       0.52       0.23\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/25      2.62G      1.809      1.862      1.724         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.0it/s 2.0s\n",
            "                   all        254        247      0.598      0.535      0.558      0.248\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/25      2.64G      1.753       1.79      1.694         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.1it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.4it/s 2.3s\n",
            "                   all        254        247      0.504      0.552      0.576      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/25      2.65G      1.713      1.737      1.668         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:03\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.5it/s 2.3s\n",
            "                   all        254        247      0.491      0.643      0.596      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/25      2.66G      1.698      1.663      1.646         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.1it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.3it/s 2.4s\n",
            "                   all        254        247      0.675       0.61      0.656      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/25      2.67G      1.664       1.61       1.61         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.1it/s 1:02\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.6it/s 2.2s\n",
            "                   all        254        247      0.687      0.565      0.607      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/25      2.68G      1.655      1.577      1.614         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.7it/s 2.2s\n",
            "                   all        254        247      0.668      0.609      0.644      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/25      2.69G      1.623      1.534       1.59         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.0it/s 1:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.5it/s 2.3s\n",
            "                   all        254        247      0.727      0.599      0.659      0.325\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/25      2.71G      1.643      1.559      1.701         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.2it/s 59.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.0it/s 2.0s\n",
            "                   all        254        247      0.682      0.591      0.664      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/25      2.72G      1.624      1.554      1.687         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.2it/s 58.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.8it/s 2.9s\n",
            "                   all        254        247      0.707      0.677      0.726      0.354\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/25      2.73G       1.57      1.439      1.656         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 58.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.9it/s 2.0s\n",
            "                   all        254        247      0.668       0.63      0.695       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/25      2.74G      1.535      1.409      1.627          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 57.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.0it/s 2.0s\n",
            "                   all        254        247      0.784      0.638      0.745      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/25      2.75G      1.528       1.39      1.621         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 58.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.7it/s 2.9s\n",
            "                   all        254        247      0.784      0.624      0.734      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/25      2.76G      1.489      1.336      1.584         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 58.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.6it/s 2.2s\n",
            "                   all        254        247      0.887      0.688       0.78      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/25      2.78G       1.46      1.272      1.566          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 58.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.0it/s 2.7s\n",
            "                   all        254        247       0.75      0.666       0.73      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/25      2.79G      1.441      1.256      1.545          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 57.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 2.6it/s 3.0s\n",
            "                   all        254        247      0.785      0.675      0.748      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/25       2.8G      1.415      1.193      1.519         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 57.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 3.9it/s 2.1s\n",
            "                   all        254        247      0.791       0.68      0.785      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/25      2.81G      1.388      1.195      1.507         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 190/190 3.3it/s 57.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 4.1it/s 2.0s\n",
            "                   all        254        247      0.785      0.725      0.796       0.42\n",
            "\n",
            "25 epochs completed in 0.447 hours.\n",
            "Optimizer stripped from /content/runs/fabric_defect_detection/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/fabric_defect_detection/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/fabric_defect_detection/weights/best.pt...\n",
            "Ultralytics 8.3.203 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.5it/s 5.5s\n",
            "                   all        254        247      0.886      0.688      0.782      0.421\n",
            "                  Hole         25         26      0.944      0.654      0.735      0.344\n",
            "                  Snag         80        148      0.761      0.595      0.703      0.333\n",
            "                 Stain         64         73      0.952      0.815      0.909      0.587\n",
            "Speed: 0.4ms preprocess, 3.4ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "\n",
            "==================================================\n",
            "TRAINING COMPLETED!\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEvaluating model performance...\")\n",
        "\n",
        "# Validate the model\n",
        "validation_results = model.val()\n",
        "\n",
        "# Extract overall metrics\n",
        "precision = validation_results.box.p.mean()   # Mean Precision\n",
        "recall = validation_results.box.r.mean()      # Mean Recall\n",
        "map50 = validation_results.box.map50          # Already a float (overall mAP@0.5)\n",
        "\n",
        "# Print in percentage format\n",
        "print(\"Validation Results:\")\n",
        "print(f\"P(%): {precision * 100:.2f}\")\n",
        "print(f\"R(%): {recall * 100:.2f}\")\n",
        "print(f\"mAP@0.5(%): {map50 * 100:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE2ijYVKIjZA",
        "outputId": "25dd11cd-b5d4-4854-9cc0-7c29fed50509"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model performance...\n",
            "Ultralytics 8.3.203 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.5¬±0.3 ms, read: 28.1¬±5.7 MB/s, size: 72.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/labels.cache... 254 images, 119 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 254/254 344.6Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 3.4it/s 4.7s\n",
            "                   all        254        247      0.883      0.689      0.782      0.422\n",
            "                  Hole         25         26      0.938      0.654      0.734      0.342\n",
            "                  Snag         80        148      0.759      0.596      0.702      0.334\n",
            "                 Stain         64         73      0.952      0.815      0.909      0.589\n",
            "Speed: 2.3ms preprocess, 4.3ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "Validation Results:\n",
            "P(%): 88.32\n",
            "R(%): 68.85\n",
            "mAP@0.5(%): 78.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on validation images\n",
        "val_images_dir = os.path.join(dataset_path, 'valid', 'images')\n",
        "test_images = [os.path.join(val_images_dir, f) for f in os.listdir(val_images_dir)[:5]]  # Test on first 5 images\n",
        "\n",
        "print(\"\\nTesting predictions on sample images...\")\n",
        "for img_path in test_images:\n",
        "    if os.path.exists(img_path):\n",
        "        results = model.predict(img_path, save=True, conf=0.5)\n",
        "        print(f\"Processed: {os.path.basename(img_path)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2zubPZEPcWb",
        "outputId": "d1a21613-510a-4e6b-a6a1-a7786e8359c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing predictions on sample images...\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/images/016088_jpg.rf.62143ddb796e5312ddcc3fb5e3454cb0.jpg: 640x640 (no detections), 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "Processed: 016088_jpg.rf.62143ddb796e5312ddcc3fb5e3454cb0.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/images/015984_jpg.rf.7532489a489e43ab87a5dfe817c6b4cb.jpg: 640x640 (no detections), 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "Processed: 015984_jpg.rf.7532489a489e43ab87a5dfe817c6b4cb.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/images/020014_jpg.rf.148fbab0d9a15646f6984820b9d7ae2c.jpg: 640x640 1 Snag, 7.3ms\n",
            "Speed: 2.2ms preprocess, 7.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "Processed: 020014_jpg.rf.148fbab0d9a15646f6984820b9d7ae2c.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/images/016077_jpg.rf.9cf076c9a8b65276664493cd94423f04.jpg: 640x640 (no detections), 7.3ms\n",
            "Speed: 1.5ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "Processed: 016077_jpg.rf.9cf076c9a8b65276664493cd94423f04.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/valid/images/015978_jpg.rf.6da9a022e730930bd952727d3209bdb2.jpg: 640x640 (no detections), 7.3ms\n",
            "Speed: 1.4ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection\u001b[0m\n",
            "Processed: 015978_jpg.rf.6da9a022e730930bd952727d3209bdb2.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nExporting model...\")\n",
        "\n",
        "# Export to different formats\n",
        "try:\n",
        "    # Export to ONNX format\n",
        "    model.export(format='onnx')\n",
        "    print(\"‚úì Model exported to ONNX format\")\n",
        "except Exception as e:\n",
        "    print(f\"‚úó ONNX export failed: {e}\")\n",
        "\n",
        "try:\n",
        "    # Export to TensorRT (if available)\n",
        "    model.export(format='engine')\n",
        "    print(\"‚úì Model exported to TensorRT format\")\n",
        "except Exception as e:\n",
        "    print(f\"‚úó TensorRT export failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nFzXTWnPrPg",
        "outputId": "b2a42400-10bd-46af-a27f-f9e526853337"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exporting model...\n",
            "Ultralytics 8.3.203 üöÄ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/fabric_defect_detection/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.69...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.0s, saved as '/content/runs/fabric_defect_detection/weights/best.onnx' (11.7 MB)\n",
            "\n",
            "Export complete (1.4s)\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/fabric_defect_detection/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/runs/fabric_defect_detection/weights/best.onnx imgsz=640 data=/content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "‚úì Model exported to ONNX format\n",
            "WARNING ‚ö†Ô∏è TensorRT requires GPU export, automatically assigning device=0\n",
            "Ultralytics 8.3.203 üöÄ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/fabric_defect_detection/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.69...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.9s, saved as '/content/runs/fabric_defect_detection/weights/best.onnx' (11.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.13.3.9...\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 7, 8400) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as /content/runs/fabric_defect_detection/weights/best.engine\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 48.8s, saved as '/content/runs/fabric_defect_detection/weights/best.engine' (15.3 MB)\n",
            "\n",
            "Export complete (48.9s)\n",
            "Results saved to \u001b[1m/content/runs/fabric_defect_detection/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/fabric_defect_detection/weights/best.engine imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/runs/fabric_defect_detection/weights/best.engine imgsz=640 data=/content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "‚úì Model exported to TensorRT format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a summary of the training\n",
        "training_summary = {\n",
        "    'dataset_path': dataset_path,\n",
        "    'model': 'YOLOv8n',\n",
        "    'epochs': training_config['epochs'],\n",
        "    'batch_size': training_config['batch'],\n",
        "    'image_size': training_config['imgsz'],\n",
        "    'training_images': train_images,\n",
        "    'validation_images': valid_images,\n",
        "    'classes': yaml_content.get('names', []),\n",
        "    'num_classes': yaml_content.get('nc', 0),\n",
        "}\n",
        "\n",
        "print(\"\\nTraining Summary:\")\n",
        "for key, value in training_summary.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Save the best model to Google Drive\n",
        "import shutil\n",
        "\n",
        "# Find the best model weights\n",
        "runs_dir = '/content/runs/fabric_defect_detection'\n",
        "best_model_path = os.path.join(runs_dir, 'weights', 'best.pt')\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    # Copy to Google Drive\n",
        "    drive_model_path = '/content/drive/MyDrive/Fabric Defects Detection/fabric_defect_yolov8n_best.pt'\n",
        "    shutil.copy2(best_model_path, drive_model_path)\n",
        "    print(f\"\\n‚úì Best model saved to Google Drive: {drive_model_path}\")\n",
        "\n",
        "    # Also save the last model\n",
        "    last_model_path = os.path.join(runs_dir, 'weights', 'last.pt')\n",
        "    if os.path.exists(last_model_path):\n",
        "        drive_last_path = '/content/drive/MyDrive/Fabric Defects Detection/fabric_defect_yolov8n_last.pt'\n",
        "        shutil.copy2(last_model_path, drive_last_path)\n",
        "        print(f\"‚úì Last model saved to Google Drive: {drive_last_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TRAINING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Check the training plots in the runs directory\")\n",
        "print(\"2. Test the model on new images\")\n",
        "print(\"3. Fine-tune hyperparameters if needed\")\n",
        "print(\"4. Deploy the model for inference\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJSDF3aPQGjB",
        "outputId": "a3fb610b-6672-468f-c6a2-5b323b0e6aac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Summary:\n",
            "  dataset_path: /content/drive/MyDrive/Fabric Defects Detection/24_09_2025_Research.v1i.yolov8\n",
            "  model: YOLOv8n\n",
            "  epochs: 25\n",
            "  batch_size: 16\n",
            "  image_size: 640\n",
            "  training_images: 3037\n",
            "  validation_images: 254\n",
            "  classes: ['Hole', 'Snag', 'Stain']\n",
            "  num_classes: 3\n",
            "\n",
            "‚úì Best model saved to Google Drive: /content/drive/MyDrive/Fabric Defects Detection/fabric_defect_yolov8n_best.pt\n",
            "‚úì Last model saved to Google Drive: /content/drive/MyDrive/Fabric Defects Detection/fabric_defect_yolov8n_last.pt\n",
            "\n",
            "==================================================\n",
            "TRAINING PIPELINE COMPLETED SUCCESSFULLY!\n",
            "==================================================\n",
            "\n",
            "Next steps:\n",
            "1. Check the training plots in the runs directory\n",
            "2. Test the model on new images\n",
            "3. Fine-tune hyperparameters if needed\n",
            "4. Deploy the model for inference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# STEP 12: Load and Test Saved Model\n",
        "# ===============================================================\n",
        "\n",
        "# ===============================================================\n",
        "#print(\"\\n\" + \"=\"*50)\n",
        "#print(\"TESTING SAVED MODEL\")\n",
        "#print(\"=\"*50)\n",
        "\n",
        "## Load the saved model\n",
        "#if os.path.exists('/content/drive/MyDrive/fabric_defect_yolov8n_best.pt'):\n",
        "#    saved_model = YOLO('/content/drive/MyDrive/fabric_defect_yolov8n_best.pt')\n",
        "#    print(\"‚úì Saved model loaded successfully\")\n",
        "#\n",
        "#    # Test on a sample image\n",
        "#    if test_images:\n",
        "#        results = saved_model.predict(test_images[0], conf=0.3)\n",
        "#        print(\"‚úì Model inference test completed\")\n",
        "#else:\n",
        "#    print(\"‚úó Saved model not found\")\n",
        "#\n",
        "#print(\"\\nAll steps completed! Your YOLOv8n fabric defect detection model is ready to use.\")\n",
        "# ==============================================================="
      ],
      "metadata": {
        "id": "D__Y4pSWSOJE"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}